{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "from torch_geometric.data import Data, download_url\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import TransE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\"bolt://localhost:7687\", auth=('neo4j', 'neo4jneo4j'), database=\"fb15k-237\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file train.txt\n",
      "Using existing file valid.txt\n",
      "Using existing file test.txt\n"
     ]
    }
   ],
   "source": [
    "url = ('https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237')\n",
    "raw_file_names = ['train.txt', 'valid.txt', 'test.txt']\n",
    "raw_dir = './data_from_url'\n",
    "for filename in raw_file_names:\n",
    "    download_url(f'{url}/{filename}', raw_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def process():\n",
    "    data_list_, node_dict_, rel_dict_ = [], {}, {}\n",
    "    for file_name in raw_file_names:\n",
    "        file_name_path = raw_dir + '/' + file_name\n",
    "        with open(file_name_path, 'r') as f:\n",
    "            data = [x.split('\\t') for x in f.read().split('\\n')[:-1]]\n",
    "\n",
    "        edge_index = torch.empty((2, len(data)), dtype=torch.long)\n",
    "        edge_type = torch.empty(len(data), dtype=torch.long)\n",
    "        for i, (src, rel, dst) in enumerate(data):\n",
    "            if src not in node_dict_:\n",
    "                node_dict_[src] = len(node_dict_)\n",
    "            if dst not in node_dict_:\n",
    "                node_dict_[dst] = len(node_dict_)\n",
    "            if rel not in rel_dict_:\n",
    "                rel_dict_[rel] = len(rel_dict_)\n",
    "\n",
    "            edge_index[0, i] = node_dict_[src]\n",
    "            edge_index[1, i] = node_dict_[dst]\n",
    "            edge_type[i] = rel_dict_[rel]\n",
    "\n",
    "        data = Data(edge_index=edge_index, edge_type=edge_type)\n",
    "        data_list_.append(data)\n",
    "\n",
    "    for data in data_list_:\n",
    "        data.num_nodes = len(node_dict_)\n",
    "\n",
    "    return data_list_, node_dict_, rel_dict_\n",
    "\n",
    "data_list, node_dict, rel_dict = process()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=4, name='entity_id', type='UNIQUENESS', schema=(:Entity {id}), ownedIndex=3 )'.}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cypher\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCREATE CONSTRAINT entity_id FOR (e:Entity) REQUIRE e.id IS UNIQUE\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/graph_data_science.py:233\u001B[0m, in \u001B[0;36mGraphDataScience.run_cypher\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner, ArrowQueryRunner):\n\u001B[1;32m    231\u001B[0m     qr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner\u001B[38;5;241m.\u001B[39mfallback_query_runner()\n\u001B[0;32m--> 233\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mqr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:61\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_driver_exception(session, e)\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 61\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Though pandas support may be experimental in the `neo4j` package, it should always\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# be supported in the `graphdatascience` package.\u001B[39;00m\n\u001B[1;32m     65\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     67\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^pandas support is experimental and might be changed or removed in future versions$\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     68\u001B[0m )\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:56\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_driver\u001B[38;5;241m.\u001B[39msession(database\u001B[38;5;241m=\u001B[39mdatabase, bookmarks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbookmarks()) \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 56\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     58\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m custom_error:\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/session.py:314\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, query, parameters, **kwargs)\u001B[0m\n\u001B[1;32m    312\u001B[0m bookmarks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bookmarks()\n\u001B[1;32m    313\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(parameters \u001B[38;5;129;01mor\u001B[39;00m {}, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 314\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_auto_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpersonated_user\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_access_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbookmarks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_min_severity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_disabled_categories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_auto_result\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/result.py:166\u001B[0m, in \u001B[0;36mResult._run\u001B[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pull()\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39msend_all()\n\u001B[0;32m--> 166\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/result.py:274\u001B[0m, in \u001B[0;36mResult._attach\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exhausted \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:180\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 180\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutinefunction(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error)\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:851\u001B[0m, in \u001B[0;36mBolt.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    847\u001B[0m \u001B[38;5;66;03m# Receive exactly one message\u001B[39;00m\n\u001B[1;32m    848\u001B[0m tag, fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minbox\u001B[38;5;241m.\u001B[39mpop(\n\u001B[1;32m    849\u001B[0m     hydration_hooks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponses[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mhydration_hooks\n\u001B[1;32m    850\u001B[0m )\n\u001B[0;32m--> 851\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfields\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midle_since \u001B[38;5;241m=\u001B[39m perf_counter()\n\u001B[1;32m    853\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_bolt5.py:376\u001B[0m, in \u001B[0;36mBolt5x0._process_message\u001B[0;34m(self, tag, fields)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_server_state_manager\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbolt_states\u001B[38;5;241m.\u001B[39mFAILED\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_failure\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_metadata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool:\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:247\u001B[0m, in \u001B[0;36mResponse.on_failure\u001B[0;34m(self, metadata)\u001B[0m\n\u001B[1;32m    245\u001B[0m handler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandlers\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    246\u001B[0m Util\u001B[38;5;241m.\u001B[39mcallback(handler)\n\u001B[0;32m--> 247\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m Neo4jError\u001B[38;5;241m.\u001B[39mhydrate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmetadata)\n",
      "\u001B[0;31mClientError\u001B[0m: {code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=4, name='entity_id', type='UNIQUENESS', schema=(:Entity {id}), ownedIndex=3 )'.}"
     ]
    }
   ],
   "source": [
    "gds.run_cypher(\"CREATE CONSTRAINT entity_id FOR (e:Entity) REQUIRE e.id IS UNIQUE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "rel_id_to_text_dict = {}\n",
    "for k in rel_dict:\n",
    "    text = k\n",
    "    id = rel_dict[k]\n",
    "    rel_id_to_text_dict[id] = text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541), Data(edge_index=[2, 17535], edge_type=[17535], num_nodes=14541), Data(edge_index=[2, 20466], edge_type=[20466], num_nodes=14541)]\n",
      "2\n",
      "tensor([  0,   1,   2,  ..., 170,  30,  38])\n"
     ]
    }
   ],
   "source": [
    "print(data_list)\n",
    "print(data_list[0].edge_index[0][1].item())\n",
    "print(data_list[0].edge_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 541 elements...\n",
      "TOTAL records: 14541 from 14541\n"
     ]
    }
   ],
   "source": [
    "def write_chunk(chunk_dict):\n",
    "    gds.run_cypher(\n",
    "            \"UNWIND $nodes AS node CREATE (n:Entity {id: node[1], value: node[0]})\",\n",
    "            params={\"nodes\": list(chunk_dict.items())},\n",
    "        )\n",
    "    print(f\"Written {len(chunk_dict)} elements...\")\n",
    "\n",
    "idx = 0\n",
    "chunk_size = 1000\n",
    "chunk_dict = {}\n",
    "for k in node_dict:\n",
    "    chunk_dict[k] = node_dict[k]\n",
    "    idx += 1\n",
    "    if idx % chunk_size == 0:\n",
    "        write_chunk(chunk_dict)\n",
    "        chunk_dict = {}\n",
    "if len(chunk_dict) > 0:\n",
    "    write_chunk(chunk_dict)\n",
    "print(f\"TOTAL records: {idx} from {len(node_dict)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_data = data_list[0]\n",
    "val_data = data_list[1]\n",
    "test_data = data_list[2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing :TEST relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 466 elements...\n",
      "TOTAL records: 20466 from 20466\n",
      "Writing :VAL relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 535 elements...\n",
      "TOTAL records: 17535 from 17535\n",
      "Writing :TRAIN relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 115 elements...\n",
      "TOTAL records: 272115 from 272115\n"
     ]
    }
   ],
   "source": [
    "def write_rel_chunk(ll:list, label):\n",
    "    gds.run_cypher(\n",
    "            \"UNWIND $list AS l MATCH (e_s:Entity {id: l[0]}), (e_t:Entity {id: l[1]}) \"+\n",
    "            \"CREATE (e_s)-[\"+label+\" { rel_id: l[2], text: l[3] }]->(e_t)\",\n",
    "            params={\"list\": ll},\n",
    "        )\n",
    "    print(f\"Written {len(ll)} elements...\")\n",
    "\n",
    "\n",
    "def create_rels(data:Data, label:str):\n",
    "    idx = 0\n",
    "    chunk_size = 1000\n",
    "    chunk_list = []\n",
    "    print(\"Writing \" + label + \" relationships\")\n",
    "    for i in range(data.num_edges):\n",
    "        source = data.edge_index[0, i].item()\n",
    "        target = data.edge_index[1, i].item()\n",
    "        id = data.edge_type[i].item()\n",
    "        text = rel_id_to_text_dict[id]\n",
    "        l = [source, target, id, text]\n",
    "        chunk_list.append(l)\n",
    "        idx += 1\n",
    "        if idx % chunk_size == 0:\n",
    "            write_rel_chunk(chunk_list, label)\n",
    "            chunk_list = []\n",
    "    if len(chunk_list) > 0:\n",
    "        write_rel_chunk(chunk_list, label)\n",
    "    print(f\"TOTAL records: {idx} from {data.num_edges}\")\n",
    "\n",
    "create_rels(test_data, \":TEST\")\n",
    "create_rels(val_data, \":VAL\")\n",
    "create_rels(train_data, \":TRAIN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Node: (:Entity {id:int, value:str})\n",
    "# Edge: [:(TRAIN|TEST|VAL) {rel_id:int, text:str}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_data_from_db(edge_label):\n",
    "    node_projection = {\"Entity\": {\"properties\": \"id\"}}\n",
    "    relationship_projection = {edge_label : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"}}\n",
    "    G, result = gds.graph.project(\n",
    "        \"fb15k-graph-t\"+edge_label,\n",
    "        node_projection,\n",
    "        relationship_projection,\n",
    "    )\n",
    "    print(f\"The projection took {result['projectMillis']} ms\")\n",
    "\n",
    "    # We can use convenience methods on `G` to check if the projection looks correct\n",
    "    print(f\"Graph '{G.name()}' node count: {G.node_count()}\")\n",
    "    print(f\"Graph '{G.name()}' node labels: {G.node_labels()}\")\n",
    "    print(f\"Graph '{G.name()}' relationship count: {G.relationship_count()}\")\n",
    "\n",
    "    return G\n",
    "\n",
    "def get_whole_dataset():\n",
    "    node_projection = {\"Entity\": {\"properties\": \"id\"}}\n",
    "    relationship_projection = {\n",
    "        \"TRAIN\" : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"},\n",
    "        \"TEST\" : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"},\n",
    "        \"VAL\" : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"},\n",
    "    }\n",
    "    G, result = gds.graph.project(\n",
    "        \"fb15k-graph-whole\",\n",
    "        node_projection,\n",
    "        relationship_projection,\n",
    "    )\n",
    "    print(f\"The projection took {result['projectMillis']} ms\")\n",
    "\n",
    "    # We can use convenience methods on `G` to check if the projection looks correct\n",
    "    print(f\"Graph '{G.name()}' node count: {G.node_count()}\")\n",
    "    print(f\"Graph '{G.name()}' node labels: {G.node_labels()}\")\n",
    "    print(f\"Graph '{G.name()}' relationship count: {G.relationship_count()}\")\n",
    "\n",
    "    return G"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection took 973 ms\n",
      "Graph 'fb15k-graph-tTRAIN' node count: 14541\n",
      "Graph 'fb15k-graph-tTRAIN' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-tTRAIN' relationship count: 272115\n",
      "The projection took 29 ms\n",
      "Graph 'fb15k-graph-tTEST' node count: 14541\n",
      "Graph 'fb15k-graph-tTEST' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-tTEST' relationship count: 20466\n",
      "The projection took 11 ms\n",
      "Graph 'fb15k-graph-tVAL' node count: 14541\n",
      "Graph 'fb15k-graph-tVAL' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-tVAL' relationship count: 17535\n",
      "The projection took 54 ms\n",
      "Graph 'fb15k-graph-whole' node count: 14541\n",
      "Graph 'fb15k-graph-whole' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-whole' relationship count: 310116\n"
     ]
    }
   ],
   "source": [
    "train_db_data_G = get_data_from_db(\"TRAIN\")\n",
    "test_db_data_G = get_data_from_db(\"TEST\")\n",
    "val_db_data_G = get_data_from_db(\"VAL\")\n",
    "db_data_G = get_whole_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# gds.graph.drop(train_db_data_G)\n",
    "# gds.graph.drop(test_db_data_G)\n",
    "# gds.graph.drop(val_db_data_G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(name=fb15k-graph-whole, node_count=14541, relationship_count=310116)\n"
     ]
    }
   ],
   "source": [
    "print(db_data_G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nodeId    id\n",
      "0       10001  9690\n",
      "1       10002  9691\n",
      "2       10003  9692\n",
      "3       10004  9693\n",
      "4       10005  9694\n",
      "...       ...   ...\n",
      "14536    9996  9685\n",
      "14537    9997  9686\n",
      "14538    9998  9687\n",
      "14539    9999  9688\n",
      "14540   10000  9689\n",
      "\n",
      "[14541 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "node_properties = gds.graph.nodeProperties.stream(\n",
    "    db_data_G,\n",
    "    [\"id\"],\n",
    "    separate_property_columns=True,\n",
    ")\n",
    "print(node_properties)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "nodeId_to_id = dict(zip(node_properties.nodeId, node_properties.id))\n",
    "id_to_nodeId = dict(zip(node_properties.id, node_properties.nodeId))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "        sourceNodeId  targetNodeId relationshipType\n0                  1             3            TRAIN\n1                  1            33            TRAIN\n2                  1           171            TRAIN\n3                  1           688            TRAIN\n4                  1          1663            TRAIN\n...              ...           ...              ...\n310111         10000           124            TRAIN\n310112         10000           124            TRAIN\n310113         10000           367            TRAIN\n310114         10000           425            TRAIN\n310115         10000           425            TRAIN\n\n[310116 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sourceNodeId</th>\n      <th>targetNodeId</th>\n      <th>relationshipType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>33</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>171</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>688</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1663</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>310111</th>\n      <td>10000</td>\n      <td>124</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310112</th>\n      <td>10000</td>\n      <td>124</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310113</th>\n      <td>10000</td>\n      <td>367</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310114</th>\n      <td>10000</td>\n      <td>425</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310115</th>\n      <td>10000</td>\n      <td>425</td>\n      <td>TRAIN</td>\n    </tr>\n  </tbody>\n</table>\n<p>310116 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_topology_df = gds.beta.graph.relationships.stream(db_data_G)\n",
    "# Let's see what we got:\n",
    "display(sample_topology_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "        sourceNodeId  targetNodeId relationshipType  rel_id\n0                  1             3            TRAIN     1.0\n1                  1            33            TRAIN   185.0\n2                  1           171            TRAIN    51.0\n3                  1           688            TRAIN   107.0\n4                  1          1663            TRAIN   201.0\n...              ...           ...              ...     ...\n310111         10000           124            TRAIN     4.0\n310112         10000           124            TRAIN     5.0\n310113         10000           367            TRAIN    80.0\n310114         10000           425            TRAIN     4.0\n310115         10000           425            TRAIN     5.0\n\n[310116 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sourceNodeId</th>\n      <th>targetNodeId</th>\n      <th>relationshipType</th>\n      <th>rel_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>TRAIN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>33</td>\n      <td>TRAIN</td>\n      <td>185.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>171</td>\n      <td>TRAIN</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>688</td>\n      <td>TRAIN</td>\n      <td>107.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1663</td>\n      <td>TRAIN</td>\n      <td>201.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>310111</th>\n      <td>10000</td>\n      <td>124</td>\n      <td>TRAIN</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>310112</th>\n      <td>10000</td>\n      <td>124</td>\n      <td>TRAIN</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>310113</th>\n      <td>10000</td>\n      <td>367</td>\n      <td>TRAIN</td>\n      <td>80.0</td>\n    </tr>\n    <tr>\n      <th>310114</th>\n      <td>10000</td>\n      <td>425</td>\n      <td>TRAIN</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>310115</th>\n      <td>10000</td>\n      <td>425</td>\n      <td>TRAIN</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>310116 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0            2\n1            2\n2            2\n3            2\n4            2\n          ... \n310111    9689\n310112    9689\n310113    9689\n310114    9689\n310115    9689\nName: sourceNodeId, Length: 310116, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rels_tmp = gds.graph.relationshipProperties.stream(db_data_G, [\"rel_id\"], separate_property_columns=True)\n",
    "display(rels_tmp)\n",
    "rels_tmp.rel_id.astype(int)\n",
    "display(rels_tmp.sourceNodeId.map(lambda x: nodeId_to_id[x]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[   2,    2,    2,  ..., 9689, 9689, 9689],\n        [   3,   32,  160,  ...,  344,  399,  399]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([  1, 185,  51,  ...,  80,   4,   5])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 310116], edge_type=[310116], num_nodes=14541)\n"
     ]
    }
   ],
   "source": [
    "topology = [rels_tmp.sourceNodeId.map(lambda x: nodeId_to_id[x]), rels_tmp.targetNodeId.map(lambda x: nodeId_to_id[x])]\n",
    "edge_index = torch.tensor(topology, dtype=torch.long)\n",
    "edge_type = torch.tensor(rels_tmp.rel_id.astype(int), dtype=torch.long)\n",
    "display(edge_index)\n",
    "display(edge_type)\n",
    "data = Data(edge_index=edge_index, edge_type=edge_type)\n",
    "data.num_nodes = len(nodeId_to_id)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 20466], edge_type=[20466], num_nodes=14541)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 17535], edge_type=[17535], num_nodes=14541)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tensor(graph):\n",
    "    rels_tmp = gds.graph.relationshipProperties.stream(graph, [\"rel_id\"], separate_property_columns=True)\n",
    "    topology = [rels_tmp.sourceNodeId.map(lambda x: nodeId_to_id[x]), rels_tmp.targetNodeId.map(lambda x: nodeId_to_id[x])]\n",
    "    edge_index = torch.tensor(topology, dtype=torch.long)\n",
    "    edge_type = torch.tensor(rels_tmp.rel_id.astype(int), dtype=torch.long)\n",
    "    data = Data(edge_index=edge_index, edge_type=edge_type)\n",
    "    data.num_nodes = len(nodeId_to_id)\n",
    "    display(data)\n",
    "    return data\n",
    "\n",
    "train_tensor = create_tensor(train_db_data_G)\n",
    "test_tensor = create_tensor(test_db_data_G)\n",
    "val_tensor = create_tensor(val_db_data_G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = TransE(\n",
    "    num_nodes=train_tensor.num_nodes,\n",
    "    num_relations=train_tensor.num_edge_types,\n",
    "    hidden_channels=50,\n",
    ").to(device)\n",
    "\n",
    "loader = model.loader(\n",
    "    head_index=train_tensor.edge_index[0],\n",
    "    rel_type=train_tensor.edge_type,\n",
    "    tail_index=train_tensor.edge_index[1],\n",
    "    batch_size=1000,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "    for head_index, rel_type, tail_index in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(head_index, rel_type, tail_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * head_index.numel()\n",
    "        total_examples += head_index.numel()\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    return model.test(\n",
    "        head_index=data.edge_index[0],\n",
    "        rel_type=data.edge_type,\n",
    "        tail_index=data.edge_index[1],\n",
    "        batch_size=20000,\n",
    "        k=10,\n",
    "    )\n",
    "\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    if epoch % 75 == 0:\n",
    "        rank, hits = test(val_tensor)\n",
    "        print(f'Epoch: {epoch:03d}, Val Mean Rank: {rank:.2f}, '\n",
    "              f'Val Hits@10: {hits:.4f}')\n",
    "\n",
    "print(model)\n",
    "idx = torch.LongTensor([1])\n",
    "print(model.rel_emb(idx))\n",
    "rank, hits_at_10 = test(test_tensor)\n",
    "print(f'Test Mean Rank: {rank:.2f}, Test Hits@10: {hits_at_10:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model, \"./model_501.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model_501_st_dict\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model = torch.load(\"./model_501.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/base/popstra/celebrity/canoodled./base/popstra/canoodled/participant\n",
      "tensor([[-0.1675,  0.0308, -0.1782,  0.1345, -0.0045,  0.0340,  0.0159, -0.3096,\n",
      "         -0.0745, -0.0816, -0.1337, -0.0214,  0.2474,  0.0208,  0.0202, -0.2063,\n",
      "          0.2327,  0.1317, -0.0562,  0.2252,  0.2233, -0.0494,  0.0689, -0.1421,\n",
      "         -0.1578, -0.2542, -0.3715, -0.0021, -0.1611,  0.2791,  0.4206, -0.0711,\n",
      "         -0.1338, -0.0318, -0.0076, -0.0900, -0.0040,  0.0135, -0.2083,  0.3131,\n",
      "         -0.2107, -0.1513, -0.2384, -0.0324,  0.2208, -0.3213,  0.1846,  0.0350,\n",
      "          0.0129, -0.3476]], grad_fn=<EmbeddingBackward0>)\n",
      "[-0.1674661487340927, 0.030775610357522964, -0.17823708057403564, 0.13445991277694702, -0.004469443578273058, 0.03396214172244072, 0.015884431079030037, -0.30958986282348633, -0.07452814280986786, -0.08162254840135574, -0.1337374746799469, -0.021421784535050392, 0.24736957252025604, 0.020815536379814148, 0.020227091386914253, -0.2062523514032364, 0.23273737728595734, 0.13173586130142212, -0.056164536625146866, 0.22517380118370056, 0.2232547402381897, -0.04943244159221649, 0.06892543286085129, -0.1420915275812149, -0.1578497439622879, -0.25417450070381165, -0.37152114510536194, -0.0021417364478111267, -0.1610587239265442, 0.27911266684532166, 0.42058438062667847, -0.07109890878200531, -0.1338321715593338, -0.031763870269060135, -0.007563647348433733, -0.09000322967767715, -0.0039866529405117035, 0.013453057035803795, -0.2083406150341034, 0.31310102343559265, -0.21068131923675537, -0.1513337641954422, -0.23836448788642883, -0.032363779842853546, 0.22075465321540833, -0.32133811712265015, 0.18457330763339996, 0.03499281033873558, 0.012892588973045349, -0.3475736081600189]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "rel_123 = 123\n",
    "print(rel_id_to_text_dict[rel_123])\n",
    "t = model.rel_emb(torch.LongTensor([rel_123]))\n",
    "print(t)\n",
    "rel_123_emb = t[0].tolist()\n",
    "print(rel_123_emb)\n",
    "print(len(rel_123_emb))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3172686696052551, 0.1578812301158905, -0.08087439835071564, -0.004596684593707323, -19.778369903564453, 0.026383597403764725, 0.13941125571727753, 0.12102761119604111, -12.489096641540527, 0.010141335427761078, -0.030836760997772217, 0.07849875837564468, 0.00281003350391984, -15.232320785522461, -0.15866008400917053, 0.19668158888816833, -0.19905561208724976, -0.5277314782142639, -0.08227643370628357, -0.17938721179962158, 0.015473323874175549, -0.06681554019451141, 0.11557577550411224, 0.05651519075036049, 0.2853202223777771, -0.05212356895208359, -0.1935097575187683, 0.27248385548591614, 0.0724930614233017, 0.0949799194931984, 0.08945981413125992, 0.04437510669231415, -0.1985391527414322, -18.364181518554688, -0.048563919961452484, -0.08124208450317383, -0.25457608699798584, -0.03215474635362625, -0.48660868406295776, -0.04439295083284378, 0.584082841873169, 0.403334379196167, 0.058653656393289566, 10.785226821899414, 0.1640355885028839, -0.1641729325056076, -0.07735151797533035, -0.04921881854534149, 0.13276174664497375, 0.1362481415271759]\n"
     ]
    }
   ],
   "source": [
    "print(model.node_emb.weight[777].tolist())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n"
     ]
    }
   ],
   "source": [
    "# write embeddings to graph\n",
    "for i in range(0, len(nodeId_to_id)):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    gds.run_cypher(\n",
    "            \"MATCH (n:Entity {id: $i}) SET n.emb = $EMBEDDING\",\n",
    "            params={\n",
    "                \"i\": i,\n",
    "                \"EMBEDDING\": model.node_emb.weight[i].tolist()\n",
    "            },\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 'fb15k-graph-test1' node count: 14541\n",
      "Graph 'fb15k-graph-test1' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-test1' relationship count: 20466\n"
     ]
    }
   ],
   "source": [
    "node_projection_test = {\"Entity\": {\"properties\": [\"id\",\"emb\"] }}\n",
    "relationship_projection_test = {\"TEST\" : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"}}\n",
    "G, result = gds.graph.project(\n",
    "        \"fb15k-graph-test1\",\n",
    "        node_projection_test,\n",
    "        relationship_projection_test,\n",
    "    )\n",
    "\n",
    "print(f\"Graph '{G.name()}' node count: {G.node_count()}\")\n",
    "print(f\"Graph '{G.name()}' node labels: {G.node_labels()}\")\n",
    "print(f\"Graph '{G.name()}' relationship count: {G.relationship_count()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "rel_148_emb = model.node_emb.weight[148].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sourceNodeId  targetNodeId      score\n",
      "0          1521           668  66.766521\n",
      "1          1521          2984  69.818382\n",
      "2          1521          6187  74.640317\n",
      "3          6430           668  52.112705\n",
      "4          6430          6187  57.971514\n",
      "5          6430          2984  61.022281\n"
     ]
    }
   ],
   "source": [
    "transe_model = gds.model.transe.create(\n",
    "    G, \"emb\", {\"REL\": rel_148_emb}\n",
    ")\n",
    "result = transe_model.predict_stream(\n",
    "    [id_to_nodeId[6180], id_to_nodeId[1454]], [id_to_nodeId[2861], id_to_nodeId[5951], id_to_nodeId[637]], \"REL\", 3, concurrency=4\n",
    ")\n",
    "print(result)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
